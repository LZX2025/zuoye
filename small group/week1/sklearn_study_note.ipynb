{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582a5c3-21e6-4d97-adb8-7066c379b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9daf083-06d2-4a5f-8475-63f4bbb8e8b3",
   "metadata": {},
   "source": [
    " ** 翻译 **\n",
    "=======\n",
    "**普通最小二乘线性回归**\n",
    "\n",
    "线性回归通过拟合一个线性模型，其系数为 w = (w1, ..., wp)，以最小化数据集中观测目标值与线性近似预测目标值之间的残差平方和。   \n",
    "**参数**\n",
    "\n",
    "- **fit_intercept** : bool，默认值为 True  \n",
    "  是否为该模型计算截距。如果设置为 False，则在计算中不使用截距（即假设数据已中心化）。\n",
    "\n",
    "- **copy_X** : bool，默认值为 True  \n",
    "  如果为 True，则会复制 X；否则，可能会覆盖 X。\n",
    "\n",
    "- **tol** : float，默认值为 1e-6  \n",
    "  解的精度（coef_）由 tol 确定，它为 lsqr 求解器指定了不同的收敛标准。在拟合稀疏训练数据时，tol 被设置为 scipy.sparse.linalg.lsqr 的 atol 和 btol。在拟合密集数据时，此参数无效。\n",
    "  .. versionadded:: 1.7\n",
    "\n",
    "- **n_jobs** : int，默认值为 None  \n",
    "  用于计算的作业数。仅在问题足够大时（即首先 n_targets > 1，其次 X 是稀疏的，或者将 positive 设置为 True 时）才会加速。None 表示 1，除非在 joblib.parallel_backend 上下文中。-1 表示使用所有处理器。更多详情请参见 Glossary <n_jobs>。\n",
    "\n",
    "- **positive** : bool，默认值为 False  \n",
    "  当设置为 True 时，强制系数为正。此选项仅支持密集数组。\n",
    "  .. versionadded:: 0.24\n",
    "\n",
    "**属性**\n",
    "\n",
    "- **coef_** : 形状为 (n_features,) 或 (n_targets, n_features) 的数组  \n",
    "  线性回归问题的估计系数。如果在拟合过程中传递了多个目标（y 是二维的），则这是一个形状为 (n_targets, n_features) 的二维数组；如果仅传递了一个目标，则这是一个长度为 n_features 的一维数组。\n",
    "\n",
    "- **rank_** : int  \n",
    "  矩阵 X 的秩。仅在 X 是密集时可用。\n",
    "\n",
    "- **singular_** : 形状为 (min(X, y),) 的数组  \n",
    "  X 的奇异值。仅在 X 是密集时可用。\n",
    "\n",
    "- **intercept_** : float 或形状为 (n_targets,) 的数组  \n",
    "  线性模型中的独立项。如果 fit_intercept = False，则设置为 0.0。\n",
    "\n",
    "- **n_features_in_** : int  \n",
    "  在 fit 期间看到的特征数量。\n",
    "  .. versionadded:: 0.24\n",
    "\n",
    "- **feature_names_in_** : 形状为 (n_features_in_,) 的 ndarray  \n",
    "  在 fit 期间看到的特征名称。仅当 X 的特征名称都是字符串时才定义。\n",
    "  .. versionadded:: 1.0\n",
    "\n",
    "**参见**\n",
    "\n",
    "- **Ridge** : 岭回归通过使用 L2 正则化对系数的大小施加惩罚，解决了普通最小二乘法的一些问题。\n",
    "- **Lasso** : Lasso 是一个线性模型，通过 L1 正则化估计稀疏系数。\n",
    "- **ElasticNet** : 弹性网是一个线性回归模型，通过同时使用 L1 和 L2 范数对系数进行正则化。\n",
    "\n",
    "**注意事项**\n",
    "\n",
    "从实现角度来看，这只是一个普通的最小二乘法（scipy.linalg.lstsq）或非负最小二乘法（scipy.optimize.nnls）的封装，作为预测器对象。\n",
    "\n",
    "**示例**\n",
    "\n",
    ">>> import numpy as np\n",
    ">>> from sklearn.linear_model import LinearRegression\n",
    ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
    ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
    ">>> reg = LinearRegression().fit(X, y)\n",
    ">>> reg.score(X, y)\n",
    "1.0\n",
    ">>> reg.coef_\n",
    "array([1., 2.])\n",
    ">>> reg.intercept_\n",
    "np.float64(3.0...)\n",
    ">>> reg.predict(np.array([[3, 5]]))\n",
    "array([16.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4aafa-0895-4189-8fa3-67651c741c91",
   "metadata": {},
   "source": [
    "## 人话 ：  \n",
    "参数判断是否需要计算截距，加速，复制等功能  \n",
    "讲一下数据结构，注意事项等 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52365f4-7e37-420a-80dc-acbd28246469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(MultiOutputMixin, RegressorMixin, LinearModel):\n",
    "    \"\"\"\n",
    "    Ordinary least squares Linear Regression.\n",
    "\n",
    "    LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
    "    to minimize the residual sum of squares between the observed targets in\n",
    "    the dataset, and the targets predicted by the linear approximation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to calculate the intercept for this model. If set\n",
    "        to False, no intercept will be used in calculations\n",
    "        (i.e. data is expected to be centered).\n",
    "\n",
    "    copy_X : bool, default=True\n",
    "        If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "    tol : float, default=1e-6\n",
    "        The precision of the solution (`coef_`) is determined by `tol` which\n",
    "        specifies a different convergence criterion for the `lsqr` solver.\n",
    "        `tol` is set as `atol` and `btol` of `scipy.sparse.linalg.lsqr` when\n",
    "        fitting on sparse training data. This parameter has no effect when fitting\n",
    "        on dense data.\n",
    "\n",
    "        .. versionadded:: 1.7\n",
    "\n",
    "    n_jobs : int, default=None\n",
    "        The number of jobs to use for the computation. This will only provide\n",
    "        speedup in case of sufficiently large problems, that is if firstly\n",
    "        `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
    "        to `True`. ``None`` means 1 unless in a\n",
    "        :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
    "        processors. See :term:`Glossary <n_jobs>` for more details.\n",
    "\n",
    "    positive : bool, default=False\n",
    "        When set to ``True``, forces the coefficients to be positive. This\n",
    "        option is only supported for dense arrays.\n",
    "\n",
    "        .. versionadded:: 0.24\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
    "        Estimated coefficients for the linear regression problem.\n",
    "        If multiple targets are passed during the fit (y 2D), this\n",
    "        is a 2D array of shape (n_targets, n_features), while if only\n",
    "        one target is passed, this is a 1D array of length n_features.\n",
    "\n",
    "    rank_ : int\n",
    "        Rank of matrix `X`. Only available when `X` is dense.\n",
    "\n",
    "    singular_ : array of shape (min(X, y),)\n",
    "        Singular values of `X`. Only available when `X` is dense.\n",
    "\n",
    "    intercept_ : float or array of shape (n_targets,)\n",
    "        Independent term in the linear model. Set to 0.0 if\n",
    "        `fit_intercept = False`.\n",
    "\n",
    "    n_features_in_ : int\n",
    "        Number of features seen during :term:`fit`.\n",
    "\n",
    "        .. versionadded:: 0.24\n",
    "\n",
    "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
    "        Names of features seen during :term:`fit`. Defined only when `X`\n",
    "        has feature names that are all strings.\n",
    "\n",
    "        .. versionadded:: 1.0\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    Ridge : Ridge regression addresses some of the\n",
    "        problems of Ordinary Least Squares by imposing a penalty on the\n",
    "        size of the coefficients with l2 regularization.\n",
    "    Lasso : The Lasso is a linear model that estimates\n",
    "        sparse coefficients with l1 regularization.\n",
    "    ElasticNet : Elastic-Net is a linear regression\n",
    "        model trained with both l1 and l2 -norm regularization of the\n",
    "        coefficients.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    From the implementation point of view, this is just plain Ordinary\n",
    "    Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
    "    (scipy.optimize.nnls) wrapped as a predictor object.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.linear_model import LinearRegression\n",
    "    >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "    >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
    "    >>> y = np.dot(X, np.array([1, 2])) + 3\n",
    "    >>> reg = LinearRegression().fit(X, y)\n",
    "    >>> reg.score(X, y)\n",
    "    1.0\n",
    "    >>> reg.coef_\n",
    "    array([1., 2.])\n",
    "    >>> reg.intercept_\n",
    "    np.float64(3.0...)\n",
    "    >>> reg.predict(np.array([[3, 5]]))\n",
    "    array([16.])\n",
    "    \"\"\"\n",
    "\n",
    "    _parameter_constraints: dict = {\n",
    "        \"fit_intercept\": [\"boolean\"],\n",
    "        \"copy_X\": [\"boolean\"],\n",
    "        \"n_jobs\": [None, Integral],\n",
    "        \"positive\": [\"boolean\"],\n",
    "        \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        fit_intercept=True,\n",
    "        copy_X=True,\n",
    "        tol=1e-6,\n",
    "        n_jobs=None,\n",
    "        positive=False,\n",
    "    ):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.copy_X = copy_X\n",
    "        self.tol = tol\n",
    "        self.n_jobs = n_jobs\n",
    "        self.positive = positive\n",
    "\n",
    "    @_fit_context(prefer_skip_nested_validation=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97714bcf-8507-431f-89c5-86edb84fec3a",
   "metadata": {},
   "source": [
    "# fit函数\n",
    "根据参数拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139cd41-ce8a-40ef-8f39-5703ed980837",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Fit linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary.\n",
    "\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Individual weights for each sample.\n",
    "\n",
    "            .. versionadded:: 0.17\n",
    "               parameter *sample_weight* support to LinearRegression.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted Estimator.\n",
    "        \"\"\"\n",
    "        n_jobs_ = self.n_jobs\n",
    "\n",
    "        accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\n",
    "\n",
    "        X, y = validate_data(\n",
    "            self,\n",
    "            X,\n",
    "            y,\n",
    "            accept_sparse=accept_sparse,\n",
    "            y_numeric=True,\n",
    "            multi_output=True,\n",
    "            force_writeable=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8549345-82e1-454c-a45c-c68ec726772f",
   "metadata": {},
   "source": [
    "检查是否含有样本权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778a648-216f-4cc5-9e60-3cc8c1bbebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        has_sw = sample_weight is not None\n",
    "        if has_sw:\n",
    "            sample_weight = _check_sample_weight(\n",
    "                sample_weight, X, dtype=X.dtype, ensure_non_negative=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960b8d1-3390-4854-a407-7b2ff819b370",
   "metadata": {},
   "source": [
    "预处理， 标准化，去中心化之类的，  \n",
    "判断是否保留原数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfd25c-adab-47a5-9caa-ad0247214680",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Note that neither _rescale_data nor the rest of the fit method of\n",
    "        # LinearRegression can benefit from in-place operations when X is a\n",
    "        # sparse matrix. Therefore, let's not copy X when it is sparse.\n",
    "        copy_X_in_preprocess_data = self.copy_X and not sp.issparse(X)\n",
    "\n",
    "        X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
    "            X,\n",
    "            y,\n",
    "            fit_intercept=self.fit_intercept,\n",
    "            copy=copy_X_in_preprocess_data,\n",
    "            sample_weight=sample_weight,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37b18e-375f-444a-a6ea-08c42d849775",
   "metadata": {},
   "source": [
    "根据是否提供了样本权重再次处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1d0ad-000e-48d4-bde3-99539521b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if has_sw:\n",
    "            # Sample weight can be implemented via a simple rescaling. Note\n",
    "            # that we safely do inplace rescaling when _preprocess_data has\n",
    "            # already made a copy if requested.\n",
    "            X, y, sample_weight_sqrt = _rescale_data(\n",
    "                X, y, sample_weight, inplace=copy_X_in_preprocess_data\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac373c-0bf4-4c2b-b073-e4950619b2a6",
   "metadata": {},
   "source": [
    "（非负约束）：处理强制系数为正的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025252fc-81a1-420e-933c-96f732025f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.positive:\n",
    "            if y.ndim < 2:\n",
    "                self.coef_ = optimize.nnls(X, y)[0]\n",
    "            else:\n",
    "                # scipy.optimize.nnls cannot handle y with shape (M, K)\n",
    "                outs = Parallel(n_jobs=n_jobs_)(\n",
    "                    delayed(optimize.nnls)(X, y[:, j]) for j in range(y.shape[1])\n",
    "                )\n",
    "                self.coef_ = np.vstack([out[0] for out in outs])\n",
    "        elif sp.issparse(X):\n",
    "            X_offset_scale = X_offset / X_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aaa469-921e-4267-b243-7c616d6ddc4f",
   "metadata": {},
   "source": [
    "处理去中心化或截掉奇异值的情况（稀疏矩阵）（稠密矩阵）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682ccad-0bff-419e-8181-9fb6c32a497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "            if has_sw:\n",
    "\n",
    "                def matvec(b):\n",
    "                    return X.dot(b) - sample_weight_sqrt * b.dot(X_offset_scale)\n",
    "\n",
    "                def rmatvec(b):\n",
    "                    return X.T.dot(b) - X_offset_scale * b.dot(sample_weight_sqrt)\n",
    "\n",
    "            else:\n",
    "\n",
    "                def matvec(b):\n",
    "                    return X.dot(b) - b.dot(X_offset_scale)\n",
    "\n",
    "                def rmatvec(b):\n",
    "                    return X.T.dot(b) - X_offset_scale * b.sum()\n",
    "\n",
    "            X_centered = sparse.linalg.LinearOperator(\n",
    "                shape=X.shape, matvec=matvec, rmatvec=rmatvec\n",
    "            )\n",
    "\n",
    "            if y.ndim < 2:\n",
    "                self.coef_ = lsqr(X_centered, y, atol=self.tol, btol=self.tol)[0]\n",
    "            else:\n",
    "                # sparse_lstsq cannot handle y with shape (M, K)\n",
    "                outs = Parallel(n_jobs=n_jobs_)(\n",
    "                    delayed(lsqr)(\n",
    "                        X_centered, y[:, j].ravel(), atol=self.tol, btol=self.tol\n",
    "                    )\n",
    "                    for j in range(y.shape[1])\n",
    "                )\n",
    "                self.coef_ = np.vstack([out[0] for out in outs])\n",
    "        else:\n",
    "            # cut-off ratio for small singular values\n",
    "            cond = max(X.shape) * np.finfo(X.dtype).eps\n",
    "            self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y, cond=cond)\n",
    "            self.coef_ = self.coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a62132-5402-480e-b96b-05a12ed3f66f",
   "metadata": {},
   "source": [
    "处理截距， 收尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859628f-77e6-4251-ac1d-d55a88ee1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    if y.ndim == 1:\n",
    "            self.coef_ = np.ravel(self.coef_)\n",
    "        self._set_intercept(X_offset, y_offset, X_scale)\n",
    "        return self\n",
    "\n",
    "    def __sklearn_tags__(self):\n",
    "        tags = super().__sklearn_tags__()\n",
    "        tags.input_tags.sparse = not self.positive\n",
    "        return tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff44b73-2319-4fbd-9595-c6f6bd823c8b",
   "metadata": {},
   "source": [
    "##总结\n",
    "========  \n",
    "LinearRegression为多种情况作了适配，高效分类处理输入，  \n",
    "数学上采用$\\beta$ = (X<sup>T</sup>X)<sup>-1</sup>X<sup>T</sup>y最小二乘法计算最优参数  \n",
    "非负约束使用非负最小二乘法（y-$\\beta$X加个绝对值）  \n",
    "对稀疏矩阵进行迭代法求解  \n",
    "添加偏置列处理截距  \n",
    "多维拆分求解\n",
    "奇异值分解或奇异值截断*\n",
    "\n",
    "对比：区别很大，优化很多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d7655-5cd1-445a-b19c-8c1645d595a7",
   "metadata": {},
   "source": [
    "### 关于SVD\n",
    "来自deep seek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac2a01-d230-4d6b-b664-3d9e7620f0f1",
   "metadata": {},
   "source": [
    "奇异值分解（Singular Value Decomposition, SVD） 是一种重要的矩阵分解方法，广泛应用于数据分析、机器学习、信号处理等领域。它将一个矩阵分解为三个特定结构的矩阵的乘积，从而揭示矩阵的内在结构和性质。以下是 SVD 的数学原理的详细解释。\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **SVD 的定义**\n",
    "对于一个实数矩阵 \\( X \\)（大小为 \\( m \\times n \\)），其奇异值分解定义为：\n",
    "\n",
    "\\[\n",
    "X = U \\Sigma V^T\n",
    "\\]\n",
    "\n",
    "其中：\n",
    "- \\( U \\) 是一个 \\( m \\times m \\) 的正交矩阵（\\( U^T U = I \\)），称为**左奇异向量矩阵**。\n",
    "- \\( \\Sigma \\) 是一个 \\( m \\times n \\) 的矩形对角矩阵，称为**奇异值矩阵**。其对角线上的元素 \\( \\sigma_i \\) 是非负的，且按从大到小排列，称为**奇异值**。\n",
    "- \\( V \\) 是一个 \\( n \\times n \\) 的正交矩阵（\\( V^T V = I \\)），称为**右奇异向量矩阵**。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **奇异值的性质**\n",
    "- 奇异值 \\( \\sigma_i \\) 是矩阵 \\( X^T X \\) 的特征值的平方根，即：\n",
    "\n",
    "\\[\n",
    "\\sigma_i = \\sqrt{\\lambda_i}\n",
    "\\]\n",
    "\n",
    "其中 \\( \\lambda_i \\) 是 \\( X^T X \\) 的特征值。\n",
    "- 奇异值是非负的，且通常按从大到小排列：\\( \\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_r > 0 \\)，其中 \\( r \\) 是矩阵 \\( X \\) 的秩。\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **几何意义**\n",
    "SVD 可以看作是对矩阵 \\( X \\) 的线性变换的分解：\n",
    "1. \\( V^T \\) 对输入空间进行旋转。\n",
    "2. \\( \\Sigma \\) 对旋转后的空间进行缩放。\n",
    "3. \\( U \\) 对缩放后的空间进行旋转。\n",
    "\n",
    "这种分解揭示了矩阵 \\( X \\) 在输入空间和输出空间中的作用。\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **SVD 的计算**\n",
    "SVD 的计算通常通过以下步骤实现：\n",
    "1. 计算 \\( X^T X \\) 和 \\( X X^T \\) 的特征值和特征向量。\n",
    "2. \\( X^T X \\) 的特征向量构成 \\( V \\)。\n",
    "3. \\( X X^T \\) 的特征向量构成 \\( U \\)。\n",
    "4. 奇异值 \\( \\sigma_i \\) 是 \\( X^T X \\) 或 \\( X X^T \\) 的特征值的平方根。\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **截断 SVD（Truncated SVD）**\n",
    "在实际应用中，通常只保留前 \\( k \\) 个最大的奇异值及其对应的奇异向量，从而得到一个低秩近似：\n",
    "\n",
    "\\[\n",
    "X \\approx U_k \\Sigma_k V_k^T\n",
    "\\]\n",
    "\n",
    "其中：\n",
    "- \\( U_k \\) 是 \\( U \\) 的前 \\( k \\) 列。\n",
    "- \\( \\Sigma_k \\) 是 \\( \\Sigma \\) 的前 \\( k \\) 个奇异值。\n",
    "- \\( V_k \\) 是 \\( V \\) 的前 \\( k \\) 列。\n",
    "\n",
    "截断 SVD 可以用于降维、去噪和数据压缩。\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **SVD 的应用**\n",
    "SVD 在机器学习和数据分析中有广泛的应用，例如：\n",
    "1. **主成分分析（PCA）**：通过 SVD 计算数据的低维表示。\n",
    "2. **推荐系统**：通过 SVD 分解用户-物品评分矩阵，预测缺失值。\n",
    "3. **图像压缩**：通过截断 SVD 减少图像的存储空间。\n",
    "4. **线性回归**：通过 SVD 求解最小二乘问题，提高数值稳定性。\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **SVD 的数学推导**\n",
    "#### （1）从特征分解出发\n",
    "对于矩阵 \\( X \\)（\\( m \\times n \\)），计算 \\( X^T X \\) 和 \\( X X^T \\)：\n",
    "- \\( X^T X \\) 是一个 \\( n \\times n \\) 的对称矩阵，其特征向量构成 \\( V \\)。\n",
    "- \\( X X^T \\) 是一个 \\( m \\times m \\) 的对称矩阵，其特征向量构成 \\( U \\)。\n",
    "\n",
    "#### （2）奇异值与特征值的关系\n",
    "- \\( X^T X \\) 的特征值为 \\( \\lambda_i \\)，奇异值为 \\( \\sigma_i = \\sqrt{\\lambda_i} \\)。\n",
    "- \\( X X^T \\) 的特征值也为 \\( \\lambda_i \\)，但可能包含额外的零特征值。\n",
    "\n",
    "#### （3）构造 \\( \\Sigma \\)\n",
    "- \\( \\Sigma \\) 是一个 \\( m \\times n \\) 的矩阵，其对角线元素为 \\( \\sigma_i \\)，其余元素为零。\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **SVD 的示例**\n",
    "假设矩阵 \\( X \\) 为：\n",
    "\n",
    "\\[\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "其 SVD 分解为：\n",
    "\n",
    "\\[\n",
    "X = U \\Sigma V^T\n",
    "\\]\n",
    "\n",
    "其中：\n",
    "- \\( U \\) 是 \\( 3 \\times 3 \\) 的正交矩阵。\n",
    "- \\( \\Sigma \\) 是 \\( 3 \\times 2 \\) 的对角矩阵。\n",
    "- \\( V \\) 是 \\( 2 \\times 2 \\) 的正交矩阵。\n",
    "\n",
    "通过计算 \\( X^T X \\) 和 \\( X X^T \\) 的特征值和特征向量，可以得到 \\( U \\)、\\( \\Sigma \\) 和 \\( V \\)。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "奇异值分解（SVD）的核心数学原理是将一个矩阵分解为三个特定结构的矩阵的乘积：\n",
    "1. 左奇异向量矩阵 \\( U \\)。\n",
    "2. 奇异值矩阵 \\( \\Sigma \\)。\n",
    "3. 右奇异向量矩阵 \\( V \\)。\n",
    "\n",
    "SVD 不仅揭示了矩阵的内在结构，还为降维、去噪、数据压缩等任务提供了强大的工具。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
